# VISION MATE

## Overview
VisionMate is an innovative assistive technology designed to empower visually impaired 
individuals by enhancing their ability to navigate and interact with their surroundings. 
Recognizing the challenges faced by the blind community in daily life, this project aims to develop 
a comprehensive solution that combines computer vision, machine learning, and real-time voice 
assistance to improve mobility and independence. 
 
The core functionality of VisionMate involves using a camera and pre-trained machine learning 
models to analyze the userâ€™s environment. The system employs the YOLO (You Only Look Once) 
model for object detection, enabling it to identify and categorize objects, obstacles, and landmarks 
in real time. Additionally, VisionMate incorporates facial recognition capabilities to identify 
familiar individuals, providing the user with timely notifications when friends or family members 
are nearby. The system also includes currency recognition to help the user differentiate between 
various denominations of money. 
 
Voice feedback is integrated throughout, ensuring that users receive continuous, accessible 
information about their environment, whether for navigation, recognizing objects, or interacting 
with familiar faces. By combining cutting-edge technologies, VisionMate aims to improve the 
safety, independence, and quality of life for visually impaired individuals.

## Model Architecture
Below is the complete model of VISION MATE:

![VISION MATE Model](https://github.com/user-attachments/assets/17078ca5-b9c6-4d42-b65c-580805e6fb10)

## Installation
To set up VISION MATE, follow these steps:
1. Clone the repository:
   ```sh
   git clone https://github.com/shadilibrahim/VisionMate.git




